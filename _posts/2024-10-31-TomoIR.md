---
layout: post
title: Tomography Through IR Light
date: 2024-10-11
description: 
tags: [Embedded-System]
categories:
giscus_comments: true
related_posts: false
toc:
  sidebar: left
---

Hand gesture identification is still one of the most compelling and difficult missions in the world of human-computer interaction, especially in AR/VR technique. To tackle this challenge, many approaches have been explored such as computer-vision-based sensing, electromyography, and ultrasound sensing. In this project, we propose a novel sensing method based on the Infrared (IR) Light. The IR light at 850nm has a strong penetrability through human's body. If we pose IR light on the wrist, the interior muscle structure change will be shown by IR light.


<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/88.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/90.jpg" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    The left-handside figure shows the IR camera view, proving we can see the IR light from our wrist. The right-hand side shows our quick 3D-prototype wristband. 
</div>


 Currently, we are processing the raw data from photodiodes and the number of IR LED and photodiode on the wristband is quite small. This is the reason why we can only identify a small number of hand gestures with big changes. As mentioned in the title, we will implement the tomography as the feature of the machine learning pipeline and increase the number of pair of IR LED and photodiode in our next step. Check out this quick demo.
 
<p><iframe src="https://www.youtube.com/embed/_R0YtRDgjHU" frameborder="0" allowfullscreen></iframe></p>
 

> Life would be too smooth if it had no rubs in it.
>