---
layout: page
title: Multimodal Sensing In The Autonomous Store
description:
img: assets/img/Store.jpg
importance: 1
category: research
related_publications: False
---

<div class="row">
    <div class="col-sm mt-3 mt-md-0">
        {% include figure.liquid loading="eager" path="assets/img/Store.jpg" title="Teaser image of UltraMic" class="img-fluid rounded z-depth-1" %}
    </div>
</div>
<div class="caption">
    In-lab store setup with camera and RFID monitoring.
</div>

Customers are required to wait in line for checking out in the traditional retail store, especially during the rush hour. The autonomous store can automatically identify what item has been taken by whom through large deployment of [camera sensing systems](https://www.youtube.com/watch?v=uY2RPlYJ0TI).

However, camera just does not work when it cannot see, which is very likely because of the shelf organization (e.g. bottom shelves) or the occlusion from human bodies. Therefore, I am trying to incorporate multiple sensing modalities like RFID, vibration, sound, weight and vision together to achieve a robust and highly autonomous self-checkout system. Please look forward to my recent work. (Hope to submit to conference next February!)



<strong style="display: block; text-align: right; margin-top: 20px; font-size: 1rem;">11-09-2024</strong>
